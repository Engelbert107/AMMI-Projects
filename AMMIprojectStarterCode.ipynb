{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AMMI-project-starter-code.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMIHLHb1p8lcRzurzCsyAE5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"HHwXn78CW9sX"},"source":["# Kaggle competition for computer vision course"]},{"cell_type":"code","metadata":{"id":"ActZLYMne_QH"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"77E1d_61W3qd"},"source":["#Imports\n","import os\n","import sys\n","import glob\n","import torch\n","import torchvision\n","\n","import numpy    as np\n","import datetime as dt\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib.pyplot   as plt\n","\n","from PIL               import Image\n","from torch.utils.data  import Dataset\n","from torch.autograd    import Variable\n","from torch.optim       import lr_scheduler\n","\n","from torch.utils.data  import Dataset, DataLoader\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from torchvision       import transforms, datasets, models\n","from os                import listdir, makedirs, getcwd, remove\n","from os.path           import isfile, join, abspath, exists, isdir, expanduser\n","\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I8l1XZD5eDDH"},"source":["data_path = \"../input/ammi-2021-convnets/\"\n","train_path = join(data_path, \"train/train\")\n","test_path = join(data_path,\"test/test\")\n","extraimage_path = join(data_path, \"extraimages/extraimages\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jxI9l715eDGG"},"source":["# Transformations for both the training and testing data\n","mean=[0.485, 0.456, 0.406]\n","std=[0.229, 0.224, 0.225]\n","\n","# Do data transforms here, Try many others\n","train_transforms = transforms.Compose([transforms.RandomRotation(30),\n","                                       transforms.RandomResizedCrop(224),\n","                                       transforms.RandomHorizontalFlip(),\n","                                       transforms.ToTensor()])\n","\n","test_transforms = transforms.Compose([ transforms.Resize(255),\n","                                       transforms.CenterCrop(224),\n","                                       transforms.ToTensor()])\n","\n","normalize = transforms.Normalize(mean=mean, std=std)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oFvokKl_eNda"},"source":["class CassavaDataset(Dataset):\n","    def __init__(self, path, transform=None):\n","        self.classes = os.listdir(path)\n","        self.path = [f\"{path}/{className}\" for className in self.classes]\n","        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n","        self.transform = transform\n","\n","        files = []\n","        for i, className in enumerate(self.classes):\n","            for fileName in self.file_list[i]:\n","                files.append([i, className, fileName])\n","        self.file_list = files\n","        files = None\n","\n","    def __len__(self):\n","        return len(self.file_list)\n","\n","    def __getitem__(self, idx):\n","        fileName = self.file_list[idx][2]\n","        classCategory = self.file_list[idx][0]\n","        im = Image.open(fileName)\n","        if self.transform:\n","            im = self.transform(im)\n","            \n","        return im.view(3, 224, 224), classCategory"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qwnBz9ZieNhK"},"source":["train_data = CassavaDataset(train_path, transform=train_transforms)\n","test_data = CassavaDataset(test_path, transform=test_transforms)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RvQ1k43OeNjk"},"source":["validation_split = .2\n","shuffle_dataset = True\n","random_seed= 42\n","\n","# Creating data indices for training and validation splits:\n","dataset_size = len(train_data)\n","indices = list(range(dataset_size))\n","split = int(np.floor(validation_split * dataset_size))\n","\n","if shuffle_dataset :\n","    np.random.seed(random_seed)\n","    np.random.shuffle(indices)\n","\n","train_indices, val_indices = indices[split:], indices[:split]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T5UU6OXAeNo7"},"source":["# Creating PT data samplers and loaders:\n","train_sampler = SubsetRandomSampler(train_indices)\n","valid_sampler = SubsetRandomSampler(val_indices)\n","\n","\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=32,\n","                                             sampler=train_sampler)\n","valid_loader = torch.utils.data.DataLoader(train_data, batch_size=32,\n","                                             sampler=valid_sampler)\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xi_FftsbeNqW"},"source":["# Device configuration\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GmK4EOh7ehHI"},"source":["# Define Models \n","\n","class Classifier(nn.Module):\n","    def __init__(self, num_classes):\n","        super(Classifier, self).__init__()\n","        # Block 1\n","        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 5, stride = 2, padding = 1)\n","        self.relu1 = nn.ReLU()\n","        self.maxpool1 = nn.MaxPool2d(kernel_size = 2)\n","\n","        #Block 2\n","        self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 5, stride = 2)\n","        self.relu2 = nn.ReLU()\n","        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n","\n","        #Block 3\n","        self.conv3 = nn.Conv2d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 2)\n","        self.relu3 = nn.ReLU()\n","        self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n","\n","        # last fully-connected layer\n","        self.fc = nn.Linear(32*3*3, num_classes)\n","\n","\n","    def forward(self, input):\n","\n","        x = self.maxpool1(self.relu1(self.conv1(input)))\n","        x = self.maxpool2(self.relu2(self.conv2(x)))\n","        x = self.maxpool3(self.relu3(self.conv3(x)))\n","\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        return x\n","\n","\n","model = Classifier(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ItPyX11HehKt"},"source":["criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bEu_R6pQeDY_"},"source":["def train(model, criterion, data_loader, optimizer, num_epochs):\n","    \"\"\"Simple training loop for a PyTorch model.\"\"\" \n","    \n","    # Make sure model is in training mode.\n","    model.train()\n","    \n","    # Move model to the device (CPU or GPU).\n","    model.to(device)\n","    \n","    # Exponential moving average of the loss.\n","    ema_loss = None\n","\n","    print('----- Training Loop -----')\n","    # Loop over epochs.\n","    for epoch in range(num_epochs):\n","        \n","      # Loop over data.\n","      for batch_idx, (features, target) in enumerate(data_loader):\n","            \n","          # Forward pass.\n","        output = model(features.to(device))\n","        loss = criterion(output.to(device), target.to(device))\n","\n","          # Backward pass.\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","      # NOTE: It is important to call .item() on the loss before summing.\n","        if ema_loss is None:\n","            ema_loss = loss.item()\n","        else:\n","            ema_loss += (loss.item() - ema_loss) * 0.01 \n","\n","      # Print out progress the end of epoch.\n","      print('Epoch: {} \\tLoss: {:.6f}'.format(epoch, ema_loss),)\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ywtmb1aoeqGW"},"source":["def test(model, data_loader):\n","    \"\"\"Measures the accuracy of a model on a data set.\"\"\" \n","    # Make sure the model is in evaluation mode.\n","    model.eval()\n","    correct = 0\n","    print('----- Model Evaluation -----')\n","    # We do not need to maintain intermediate activations while testing.\n","    with torch.no_grad():\n","        \n","        # Loop over test data.\n","        for features, target in data_loader:\n","          \n","            # Forward pass.\n","            output = model(features.to(device))\n","            \n","            # Get the label corresponding to the highest predicted probability.\n","            pred = output.argmax(dim=1, keepdim=True)\n","            \n","            # Count number of correct predictions.\n","            correct += pred.cpu().eq(target.view_as(pred)).sum().item()\n","\n","    # Print test accuracy.\n","    percent = 100. * correct / len(data_loader.dataset)\n","    print(f'Test accuracy: {correct} / {len(data_loader.dataset)} ({percent:.0f}%)')\n","    torch.save(model.state_dict(), 'model.ckpt')\n","    return percent"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"27_EXhDLetuC"},"source":["num_epochs = 5\n","train(model, criterion, train_loader, optimizer, num_epochs=num_epochs)\n","test(model, valid_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z06FPE8ketwT"},"source":["# test(model, test_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D8kshJFxetyf"},"source":["# Make submission here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_yDRLZ3Net0q"},"source":[""],"execution_count":null,"outputs":[]}]}